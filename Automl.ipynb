{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a93235f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace, Experiment\n",
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ea6e376",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = Experiment(workspace=ws, name=\"udacity-project\")\n",
    "\n",
    "run = exp.start_logging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fcf0a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating......\n",
      "SucceededProvisioning operation finished, operation \"Succeeded\"\n",
      "Succeeded\n",
      "AmlCompute wait for completion finished\n",
      "\n",
      "Minimum number of nodes requested have been provisioned\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "# TODO: Create compute cluster\n",
    "# Use vm_size = \"Standard_D2_V2\" in your provisioning configuration.\n",
    "# max_nodes should be no greater than 4.\n",
    "\n",
    "# Choose a name for your CPU cluster\n",
    "cpu_cluster_name = \"UdacityProject2\"\n",
    "\n",
    "# Verify that cluster does not exist already\n",
    "try:\n",
    "    cpu_cluster = ComputeTarget(workspace=ws, name=cpu_cluster_name)\n",
    "    print('Found existing cluster')\n",
    "except ComputeTargetException:\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D2_V2',\n",
    "                                                           max_nodes=4)\n",
    "    cpu_cluster = ComputeTarget.create(ws, cpu_cluster_name, compute_config)\n",
    "\n",
    "cpu_cluster.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e774136d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.data.dataset_factory import TabularDatasetFactory\n",
    "\n",
    "# Create TabularDataset using TabularDatasetFactory\n",
    "# Data is available at: \n",
    "# \"https://automlsamplenotebookdata.blob.core.windows.net/automl-sample-notebook-data/bankmarketing_train.csv\"\n",
    "path = 'https://automlsamplenotebookdata.blob.core.windows.net/automl-sample-notebook-data/bankmarketing_train.csv'\n",
    "autods = TabularDatasetFactory.from_delimited_files(path = path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2583e7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def clean_data(data):\n",
    "    # Dict for cleaning data\n",
    "    months = {\"jan\":1, \"feb\":2, \"mar\":3, \"apr\":4, \"may\":5, \"jun\":6, \"jul\":7, \"aug\":8, \"sep\":9, \"oct\":10, \"nov\":11, \"dec\":12}\n",
    "    weekdays = {\"mon\":1, \"tue\":2, \"wed\":3, \"thu\":4, \"fri\":5, \"sat\":6, \"sun\":7}\n",
    "\n",
    "    # Clean and one hot encode data\n",
    "    x_df = data.to_pandas_dataframe().dropna()\n",
    "    jobs = pd.get_dummies(x_df.job, prefix=\"job\")\n",
    "    x_df.drop(\"job\", inplace=True, axis=1)\n",
    "    x_df = x_df.join(jobs)\n",
    "    x_df[\"marital\"] = x_df.marital.apply(lambda s: 1 if s == \"married\" else 0)\n",
    "    x_df[\"default\"] = x_df.default.apply(lambda s: 1 if s == \"yes\" else 0)\n",
    "    x_df[\"housing\"] = x_df.housing.apply(lambda s: 1 if s == \"yes\" else 0)\n",
    "    x_df[\"loan\"] = x_df.loan.apply(lambda s: 1 if s == \"yes\" else 0)\n",
    "    contact = pd.get_dummies(x_df.contact, prefix=\"contact\")\n",
    "    x_df.drop(\"contact\", inplace=True, axis=1)\n",
    "    x_df = x_df.join(contact)\n",
    "    education = pd.get_dummies(x_df.education, prefix=\"education\")\n",
    "    x_df.drop(\"education\", inplace=True, axis=1)\n",
    "    x_df = x_df.join(education)\n",
    "    x_df[\"month\"] = x_df.month.map(months)\n",
    "    x_df[\"day_of_week\"] = x_df.day_of_week.map(weekdays)\n",
    "    x_df[\"poutcome\"] = x_df.poutcome.apply(lambda s: 1 if s == \"success\" else 0)\n",
    "\n",
    "    x_df['y_cleaned'] = x_df.pop(\"y\").apply(lambda s: 1 if s == \"yes\" else 0)\n",
    "    \n",
    "    return x_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9702440f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from train import clean_data\n",
    "\n",
    "# Use the clean_data function to clean your data.\n",
    "ds = clean_data(autods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec2d6db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_data, validation_data = ds.random_split(percentage=0.8, seed=223)\n",
    "# label_column_name = \"y_cleaned\"\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(ds, test_size=0.2, random_state=11)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e21ce171",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_column_name = \"y_cleaned\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1eae501a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.automl import AutoMLConfig\n",
    "\n",
    "# Set parameters for AutoMLConfig\n",
    "# NOTE: DO NOT CHANGE THE experiment_timeout_minutes PARAMETER OR YOUR INSTANCE WILL TIME OUT.\n",
    "# If you wish to run the experiment longer, you will need to run this notebook in your own\n",
    "# Azure tenant, which will incur personal costs.\n",
    "automl_settings = {\n",
    "    \"n_cross_validations\": 5,\n",
    "    \"primary_metric\": \"average_precision_score_weighted\",\n",
    "    \"verbosity\": logging.INFO,\n",
    "    \"enable_stack_ensemble\": False,\n",
    "}\n",
    "\n",
    "automl_config = AutoMLConfig(\n",
    "    task=\"classification\",\n",
    "    debug_log=\"automl_errors.log\",\n",
    "    training_data=train,\n",
    "    label_column_name=label_column_name,\n",
    "    **automl_settings)\n",
    "\n",
    "# automl_config = AutoMLConfig(\n",
    "#     experiment_timeout_minutes=30,\n",
    "#     task='Classification',\n",
    "#     primary_metric='accuracy',\n",
    "#     training_data=x_train,\n",
    "#     label_column_name='y_cleaned',\n",
    "#     n_cross_validations=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aec62c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No run_configuration provided, running on local with default configuration\n",
      "Running in the active local environment.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>udacity-project</td><td>AutoML_c7370f0e-f69a-4a25-9bd2-2cab26c15682</td><td>automl</td><td>Preparing</td><td><a href=\"https://ml.azure.com/runs/AutoML_c7370f0e-f69a-4a25-9bd2-2cab26c15682?wsid=/subscriptions/cdbe0b43-92a0-4715-838a-f2648cc7ad21/resourcegroups/aml-quickstarts-150678/workspaces/quick-starts-ws-150678&amp;tid=660b3398-b80e-49d2-bc5b-ac1dc93b5254\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current status: DatasetEvaluation. Gathering dataset statistics.\n",
      "Current status: FeaturesGeneration. Generating features for the dataset.\n",
      "Current status: DatasetFeaturization. Beginning to fit featurizers and featurize the dataset.\n",
      "Current status: DatasetFeaturizationCompleted. Completed fit featurizers and featurizing the dataset.\n",
      "Current status: DatasetBalancing. Performing class balancing sweeping\n",
      "Current status: DatasetCrossValidationSplit. Generating individually featurized CV splits.\n",
      "\n",
      "****************************************************************************************************\n",
      "DATA GUARDRAILS: \n",
      "\n",
      "TYPE:         Class balancing detection\n",
      "STATUS:       ALERTED\n",
      "DESCRIPTION:  To decrease model bias, please cancel the current run and fix balancing problem.\n",
      "              Learn more about imbalanced data: https://aka.ms/AutomatedMLImbalancedData\n",
      "DETAILS:      Imbalanced data can lead to a falsely perceived positive effect of a model's accuracy because the input data has bias towards one class.\n",
      "+---------------------------------+---------------------------------+--------------------------------------+\n",
      "|Size of the smallest class       |Name/Label of the smallest class |Number of samples in the training data|\n",
      "+=================================+=================================+======================================+\n",
      "|2974                             |1                                |26360                                 |\n",
      "+---------------------------------+---------------------------------+--------------------------------------+\n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "TYPE:         Missing feature values imputation\n",
      "STATUS:       PASSED\n",
      "DESCRIPTION:  No feature missing values were detected in the training data.\n",
      "              Learn more about missing value imputation: https://aka.ms/AutomatedMLFeaturization\n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "TYPE:         High cardinality feature detection\n",
      "STATUS:       PASSED\n",
      "DESCRIPTION:  Your inputs were analyzed, and no high cardinality features were detected.\n",
      "              Learn more about high cardinality feature handling: https://aka.ms/AutomatedMLFeaturization\n",
      "\n",
      "****************************************************************************************************\n",
      "Current status: ModelSelection. Beginning model selection.\n",
      "\n",
      "****************************************************************************************************\n",
      "ITERATION: The iteration being evaluated.\n",
      "PIPELINE: A summary description of the pipeline being evaluated.\n",
      "DURATION: Time taken for the current iteration.\n",
      "METRIC: The result of computing score on the fitted pipeline.\n",
      "BEST: The best observed score thus far.\n",
      "****************************************************************************************************\n",
      "\n",
      " ITERATION   PIPELINE                                       DURATION      METRIC      BEST\n",
      "         0   MaxAbsScaler LightGBM                          0:00:29       0.9562    0.9562\n",
      "         1   MaxAbsScaler XGBoostClassifier                 0:00:36       0.9567    0.9567\n",
      "         2   MaxAbsScaler ExtremeRandomTrees                0:00:28       0.9182    0.9567\n",
      "         3   MaxAbsScaler ExtremeRandomTrees                0:00:29       0.9351    0.9567\n",
      "         4   MaxAbsScaler ExtremeRandomTrees                0:00:28       0.9142    0.9567\n",
      "         5   MaxAbsScaler RandomForest                      0:00:25       0.9258    0.9567\n",
      "         6   MaxAbsScaler ExtremeRandomTrees                0:00:29       0.9303    0.9567\n",
      "         7   MaxAbsScaler RandomForest                      0:00:29       0.9315    0.9567\n",
      "         8   MaxAbsScaler RandomForest                      0:00:26       0.9308    0.9567\n",
      "         9   StandardScalerWrapper XGBoostClassifier        0:00:27       0.9516    0.9567\n",
      "        10   MaxAbsScaler SGD                               0:00:26       0.9454    0.9567\n",
      "        11   MaxAbsScaler ExtremeRandomTrees                0:00:27       0.9165    0.9567\n",
      "        12   MaxAbsScaler RandomForest                      0:00:24       0.9283    0.9567\n",
      "        13   MaxAbsScaler RandomForest                      0:00:27       0.9287    0.9567\n",
      "        14   MaxAbsScaler ExtremeRandomTrees                0:00:28       0.9112    0.9567\n",
      "        15   SparseNormalizer ExtremeRandomTrees            0:00:30       0.9308    0.9567\n",
      "        16   MaxAbsScaler ExtremeRandomTrees                0:00:32       0.9210    0.9567\n",
      "        17   MaxAbsScaler LightGBM                          0:00:30       0.9562    0.9567\n",
      "        18   TruncatedSVDWrapper XGBoostClassifier          0:00:51       0.9512    0.9567\n",
      "        19   MaxAbsScaler SGD                               0:00:28       0.9459    0.9567\n",
      "        20   TruncatedSVDWrapper XGBoostClassifier          0:02:21       0.9523    0.9567\n",
      "        21   MaxAbsScaler LightGBM                          0:00:33       0.9486    0.9567\n",
      "        22   TruncatedSVDWrapper XGBoostClassifier          0:00:47       0.9513    0.9567\n",
      "        23   MaxAbsScaler LightGBM                          0:00:29       0.9522    0.9567\n",
      "        24   StandardScalerWrapper LogisticRegression       0:02:10       0.9462    0.9567\n",
      "        25   StandardScalerWrapper XGBoostClassifier        0:00:30       0.7999    0.9567\n",
      "        26   StandardScalerWrapper XGBoostClassifier        0:01:05       0.9572    0.9572\n",
      "        27   StandardScalerWrapper XGBoostClassifier        0:01:48       0.9537    0.9572\n",
      "        28   MaxAbsScaler LightGBM                          0:00:30       0.9561    0.9572\n",
      "        29   StandardScalerWrapper LogisticRegression       0:00:29       0.9465    0.9572\n",
      "        30   TruncatedSVDWrapper XGBoostClassifier          0:01:07       0.9528    0.9572\n",
      "        31   StandardScalerWrapper LightGBM                 0:00:44       0.9562    0.9572\n",
      "        32   MaxAbsScaler LightGBM                          0:00:35       0.9495    0.9572\n",
      "        33   MaxAbsScaler LightGBM                          0:00:28       0.9547    0.9572\n",
      "        34   StandardScalerWrapper LightGBM                 0:00:29       0.9561    0.9572\n",
      "        35   TruncatedSVDWrapper XGBoostClassifier          0:03:42       0.9535    0.9572\n",
      "        36   MaxAbsScaler LightGBM                          0:00:31       0.9565    0.9572\n",
      "        37   VotingEnsemble                                 0:00:44       0.9577    0.9577\n",
      "Stopping criteria reached at iteration 38. Ending experiment.\n",
      "****************************************************************************************************\n",
      "Current status: BestRunExplainModel. Best run model explanations started\n",
      "Current status: ModelExplanationDataSetSetup. Model explanations data setup completed\n",
      "Current status: PickSurrogateModel. Choosing LightGBM as the surrogate model for explanations\n",
      "Current status: EngineeredFeatureExplanations. Computation of engineered features started\n",
      "Current status: EngineeredFeatureExplanations. Computation of engineered features completed\n",
      "Current status: RawFeaturesExplanations. Computation of raw features started\n",
      "Current status: RawFeaturesExplanations. Computation of raw features completed\n",
      "Current status: BestRunExplainModel. Best run model explanations completed\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "# Submit your automl run\n",
    "\n",
    "run = exp.submit(config = automl_config, show_output = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48a8d9ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('datatransformer',\n",
       "                 DataTransformer(enable_dnn=False, enable_feature_sweeping=True, feature_sweeping_config={}, feature_sweeping_timeout=86400, featurization_config=None, force_text_dnn=False, is_cross_validation=True, is_onnx_compatible=False, observer=None, task='classification', working_dir='/mnt/batch/tasks/shared/LS_root/mount...\n",
       "    gpu_training_param_dict={'processing_unit_type': 'cpu'}\n",
       "), random_state=0, reg_alpha=2.3958333333333335, reg_lambda=0.8333333333333334, subsample=0.9, tree_method='hist'))], verbose=False))], flatten_transform=None, weights=[0.3333333333333333, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.2, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667]))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve and save your best automl model.\n",
    "\n",
    "best_run, best_model = run.get_output()\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "74c7b72a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>udacity-project</td><td>AutoML_c7370f0e-f69a-4a25-9bd2-2cab26c15682_37</td><td></td><td>Completed</td><td><a href=\"https://ml.azure.com/runs/AutoML_c7370f0e-f69a-4a25-9bd2-2cab26c15682_37?wsid=/subscriptions/cdbe0b43-92a0-4715-838a-f2648cc7ad21/resourcegroups/aml-quickstarts-150678/workspaces/quick-starts-ws-150678&amp;tid=660b3398-b80e-49d2-bc5b-ac1dc93b5254\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.run.Run?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Run(Experiment: udacity-project,\n",
       "Id: AutoML_c7370f0e-f69a-4a25-9bd2-2cab26c15682_37,\n",
       "Type: None,\n",
       "Status: Completed)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469e96fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
